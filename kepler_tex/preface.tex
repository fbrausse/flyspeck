

In 1611, Kepler wrote a small booklet in which he asserted that the familiar cannonball arrangement of congruent balls in space achieves the highest possible density.  That is, no other arrangement can fill a larger fraction of space.  This statement has come to be known as the packing problem, or the Kepler conjecture.  In 1900, Hilbert made this part of his eighteenth problem.  This book presents a solution to the packing problem.

\section{Formalization Blueprint}

Ten years have passed since a proof was first
obtained. Why give a new presentation of the proof?

The original proof was long and complex.  The complexity was not
because of conceptual challenges.  In fact, the proof makes only
modest demands on the theoretical training of the reader.  It is
possible to read and understand the proof with a knowledge of a
limited body of mathematics, such as basic calculus and elementary
Euclidean geometry.

Nevertheless, the proof involves many  calculation that are routine
and yet sometimes long and tedious.  The proof relies on the results
of computer programs.  An error in any calculation or a bug in the
computer code has the potential of toppling the entire proof.

The referees were conscientious and checked many of the
calculations.  However, the computer code was never seriously
checked, and even the most conscientious auditor can make an
occasional slip.

After all is said and done, no proof is more reliable than the
reliability of the processes that are used to verify its
correctness.  These processes include the checking that the author
makes before releasing the proof for public scrutiny, the checking
of the referees, and the checking done by readers over time.

In recent years, I have been increasingly preoccupied by the
processes that we rely on to insure the correctness of complex
proofs. Researchers from Frege to G\"odel, who solved a problem of
rigor in mathematics, found a theoretical solution but did not
extinguish the burning fire at the foundations of mathematics,
because they omitted the practical implementation. Some, such as
Bourbaki, have even gone so far as to claim that ``formalized
mathematics cannot in practice be written down in full'' and call
such a project
``absolutely unrealizable'' \cite[p 10,11]{Bo}. % Theory of Sets, page 10,11.

While it is true that formal proofs may be too long to print,
computers -- which do not have the same limitations as paper -- have
become the natural host of formal mathematics. In recent decades,
logicians and computer scientists have reworked the foundations of
mathematics, putting them in an efficient form designed for real use
on real computers.

For the first time in history, it is possible to generate and verify
every single logical inference of major mathematical theorems.  This
has now been done for the four-color theorem, the prime number
theorem, the Jordan curve theorem, the Brouwer fixed point theorem,
the fundamental theorem of calculus, and many other theorems.  Freek
Wiedijk reports that 63\% of a list of 100 ``top'' theorems have now
been checked formally \cite{freek}.

Some mathematicians remain skeptical of the process because
computers have been used to generate and verify the logical
inferences.  Computers are notoriously imperfect, with flaws ranging
from software bugs to defective chips.  Even if a computer verifies
the inferences, who will verify the verifier, or then verify the
verifier of the verifier?  Indeed, it would be unscientific of us to
place an unmerited trust in computers.

As I said above, I believe that mathematical proofs are ultimately
no more reliable that the processes we use to verify them.  We have
two competing verification processes.  The first is the traditional
process of referees, which depends largely on the luck of the draw
-- some referees are meticulous, others are careless.   The second
process is formal computer verification. In this case, the process
is less dependent on the whims of a particular referee.

In my view, choosing between the conventional referee process and
computer verification is like choosing between choosing between an
hourglass and an atomic clock as the scientific standard of time. It
impedes science to hold to the hourglass because of imperfections in
the atomic clock.

My standard of proof has become the highest scientific standard
available by current technology.  Today the highest available
standard is formal verification by computer.  This standard will
continue to evolve with the advancement of technology.

My dream is to have some day a fully formally verified solution to
the packing problem.
This has not been done, but progress is being
made.  This book is an attempt to rearrange the proof
in such a way to make formal verification easier to do.

The proof style of formal proofs is different from that of
conventional proofs.  It is better to have a large number of short
snappy proofs, rather than a few ingenious ones.  Humans enjoy
surprising new perspectives, but computers prefer standardization.
Despite these differences, I have worked to make this a proof that
will be valuable both to humans and to computers.


\section{Structure of this Book}

Because of the complexity of the solution to this problem, it is particularly important for the reader to maintain a clear view of the structure and organization of this book. 


The introductory essays describe the major ideas,  methods, and organization of the proof.  There is an essay on each major computer component of the proof. The purpose is to provide a panoramic view of proof, to provide intuition about proof strategies.  After reading this part of the book, the reading should understand what the proof is all about, without yet dipping into technical details.  

The part on foundations provides background material about constructions in discrete geometry that have relevance beyond the packing problem.  There are four chapters in this part.  The first covers trigonometric identities and basic vector geometry.  The second treats volume from an elementary point of view.  The third chapter covers planar graph theory from a purely combinatorial point of view.  The fourth chapter covers fans, which gives planar graphs from a more geometric point of view.

The next part of the book gives the solution to the packing problem.  The first chapter in this part gives a top-level overview of the major steps of the proof.  It describes how the problem can be reduced from a problem in infinitely many variables to a problem in finitely many variables.  The remaining chapters in this part flesh out that skeleton.


Beyond the text,
the proof relies on three separate external bodies of computer code.  These will be described in much greater detail at various places in the book.  These external bodies of code are called
\begin{enumerate}
\item Tame Hypermap Generation,
\item Interval Arithmetic,
\item Linear Programming.
\end{enumerate}
The tame hypermap generation is an stand-alone program that is run once at a specific point of the proof.  It carries out a combinatorial classification of planar graphs satisfying a certain restrictive list of properties.  The reader can safely ignore this computer program until reaching the relevant point in the proof.   By contrast, the interval arithmetic is a collection of nearly one thousand inequalities that have been proved by computer.   These inequalities are spread throughout the proof and appear throughout this book.  On first reading, the reader is encouraged to accept these inequalities as axiomatically given facts.   Detailed documentation about these inequalities is available for those who wish to follow up later on the computer-generated proofs of these inequalities.  The final stage of the proof consists entirely of linear programming.  There are also several small linear programs that appear in scattered places in the book.



\section{Thanks}

I am particularly grateful to Sam Ferguson, for the years that
he spent working on this problem with me.  I also thank the early editors
R. MacPherson, G. Fejes T\'oth, and J. Lagarias for their work
to improve a technically challenging piece of mathematics.  

Many colleagues in the formal theorem proving community have helped me to learn the theory and the tools.  Others have made significant contributions to the flyspeck formalization project.  I wish to thank 
Nguyen Quang Truong % fix accents. (he found a mistake)
Nguyen Tat Thang % fix accents. (he found a mistake)
J. Avigad, M. Adams, F. Wiedijk,  T. Nipkow, J. Harrison, S. McLaughlin, G. Bauer, S. Obua, and R. Zumkeller.   Much of the material from this book was covered in a course on discrete geometry and computers at the University of Pittsburgh.  I would like to thank the members of that class for working through the organization of the text with me.

This book has been written in part during a sabbatical leave from the University of Pittsburgh.  I wish to thank the many institutions that supported
me during this period: the Max Planck Institute in Bonn, the \'Ecole Normale Sup\'erieure,  the Institute of Math
in Hanoi, Radboud Univeristy in Nijmegen, and the University of Strasbourg.
I thank those that made these visits possible: G. Mints, F. Loeser, F. Lecomte, H. Barendregt, Ha Huy Khoai and Ng\^o Vi\d{\^e}t Trung.


\bigskip
\hbox{}



\bigskip
\hbox{}

{
\parindent=0pt
\obeylines

Thomas C. Hales
Pittsburgh, PA
September, 2009

}







